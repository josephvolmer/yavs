"""AI-powered vulnerability summarization with multi-provider support."""

import os
from typing import List, Dict, Any, Optional
from datetime import datetime

from .provider import create_provider, AIProvider
from ..utils.logging import LoggerMixin


class Summarizer(LoggerMixin):
    """
    AI-powered summarizer for vulnerability findings.

    Uses AI (Claude or OpenAI) to:
    - Generate executive summaries
    - Prioritize findings
    - Identify patterns and trends
    - Provide actionable insights
    """

    def __init__(
        self,
        model: Optional[str] = None,
        provider: Optional[str] = None,
        api_key: Optional[str] = None,
        max_tokens: int = 4096,
        temperature: float = 0.0
    ):
        """
        Initialize summarizer.

        Args:
            model: AI model to use (provider-specific)
            provider: AI provider ('anthropic' or 'openai')
            api_key: API key (or from environment)
            max_tokens: Maximum tokens for response
            temperature: Sampling temperature (0.0 for deterministic)
        """
        self.max_tokens = max_tokens
        self.temperature = temperature

        # Create provider
        self.provider: AIProvider = create_provider(
            config_provider=provider,
            config_model=model,
            api_key=api_key
        )

        # Log which provider we're using
        self.logger.info(
            f"[bold cyan]AI Provider:[/bold cyan] {self.provider.provider_name}",
            extra={"markup": True}
        )
        self.logger.info(
            f"[bold cyan]AI Model:[/bold cyan] {self.provider.model_name}",
            extra={"markup": True}
        )

    def summarize(self, findings: List[Dict[str, Any]]) -> str:
        """
        Generate an executive summary of all findings.

        Args:
            findings: List of normalized findings

        Returns:
            Markdown-formatted summary with provider attribution
        """
        if not findings:
            return "No vulnerabilities found."

        self.logger.info(f"Generating AI summary for {len(findings)} findings")

        # Build statistics
        stats = self._get_statistics(findings)

        # Build prompt
        prompt = self._build_summary_prompt(findings, stats)

        # Call AI provider
        summary = self.provider.create_completion(
            prompt=prompt,
            max_tokens=self.max_tokens,
            temperature=self.temperature
        )

        self.logger.info("AI summary generated successfully")

        # Add attribution footer
        attribution = self._build_attribution()
        full_summary = f"{summary}\n\n{attribution}"

        return full_summary

    def _build_attribution(self) -> str:
        """Build attribution footer for summary."""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S UTC")
        return f"""---
*Generated by {self.provider.provider_name} ({self.provider.model_name}) on {timestamp}*"""

    def _build_summary_prompt(
        self,
        findings: List[Dict[str, Any]],
        stats: Dict[str, Any]
    ) -> str:
        """Build prompt for summary generation."""
        # Limit findings to top 50 for context window
        top_findings = findings[:50]

        findings_text = "\n".join([
            f"- [{f.get('severity')}] {f.get('file', 'unknown')}: {f.get('message')} (Tool: {f.get('tool')})"
            for f in top_findings
        ])

        prompt = f"""You are a security analyst. Provide an ULTRA-CONCISE executive summary for developers.

## Statistics
- Total: {stats['total']} | Critical: {stats['by_severity'].get('CRITICAL', 0)} | High: {stats['by_severity'].get('HIGH', 0)} | Medium: {stats['by_severity'].get('MEDIUM', 0)} | Low: {stats['by_severity'].get('LOW', 0)}
- Dependencies: {stats['by_category'].get('dependency', 0)} | SAST: {stats['by_category'].get('sast', 0)} | Compliance: {stats['by_category'].get('compliance', 0)}

## Top {len(top_findings)} Findings:
{findings_text}

Your response MUST follow this EXACT structure:

## Risk Level
One sentence: Overall severity (use **bold** for risk level: **CRITICAL**, **HIGH**, **MODERATE**, **LOW**).

## Immediate Actions
Bullet list (max 3 items): Most critical fixes needed NOW.
- Use **bold** for severity tags
- Each item: one line only

## Fix Priority
Numbered list (max 3 items): What to fix in order.
1. First priority (one line)
2. Second priority (one line)
3. Third priority (one line)

CRITICAL REQUIREMENTS:
- Maximum 150 words total
- Use **bold** for emphasis
- NO paragraphs - bullets and short sentences only
- NO emojis
- NO code blocks in summary"""

        return prompt

    def _get_statistics(self, findings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Calculate statistics from findings."""
        from collections import defaultdict

        stats = {
            "total": len(findings),
            "by_severity": defaultdict(int),
            "by_category": defaultdict(int),
            "by_tool": defaultdict(int),
        }

        for finding in findings:
            stats["by_severity"][finding.get("severity", "UNKNOWN")] += 1
            stats["by_category"][finding.get("category", "unknown")] += 1
            stats["by_tool"][finding.get("tool", "unknown")] += 1

        # Convert to regular dicts
        stats["by_severity"] = dict(stats["by_severity"])
        stats["by_category"] = dict(stats["by_category"])
        stats["by_tool"] = dict(stats["by_tool"])

        return stats

    def get_provider_info(self) -> Dict[str, str]:
        """Get provider information for metadata."""
        return {
            "provider": self.provider.provider_name,
            "model": self.provider.model_name
        }
